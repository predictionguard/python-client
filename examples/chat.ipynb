{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Chat Completions with Prediction Guard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import os\n",
    "import json\n",
    "\n",
    "from predictionguard import PredictionGuard\n",
    "\n",
    "\n",
    "# Set your Prediction Guard token and url as an environmental variable.\n",
    "os.environ[\"PREDICTIONGUARD_API_KEY\"] = \"<api key>\"\n",
    "os.environ[\"PREDICTIONGUARD_URL\"] = \"<url>\"\n",
    "\n",
    "# Or set your Prediction Guard token and url when initializing the PredictionGuard class.\n",
    "client = PredictionGuard(\n",
    "    api_key=\"<api_key>\",\n",
    "    url=\"<url>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Chat Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that provide clever and sometimes funny responses.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tell me a funny joke about pirates.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"Hermes-3-Llama-3.1-8B\",\n",
    "    messages=messages,\n",
    "    max_completion_tokens=500,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "print(json.dumps(\n",
    "    chat_response,\n",
    "    sort_keys=True,\n",
    "    indent=4,\n",
    "    separators=(',', ': ')\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Chat Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that provide clever and sometimes funny responses.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Write me a children's story about an elf warrior.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for res in client.chat.completions.create(\n",
    "    model=\"Hermes-3-Llama-3.1-8B\",\n",
    "    messages=messages,\n",
    "    max_completion_tokens=100,\n",
    "    stream=True\n",
    "):\n",
    "    # Use 'end' parameter in print function to avoid new lines.\n",
    "    print(res[\"data\"][\"choices\"][0][\"delta\"][\"content\"], end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                # Text to use for inference.\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"What's in this image?\"\n",
    "            },\n",
    "            {\n",
    "                # Image to use for inference. Accepts image urls, files, and base64 encoded images, all under the \"image_url\" param.\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "vision_response = client.chat.completions.create(\n",
    "    model=\"Qwen2.5-VL-7B-Instruct\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(json.dumps(\n",
    "    vision_response,\n",
    "    sort_keys=True,\n",
    "    indent=4,\n",
    "    separators=(',', ': ')\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = client.chat.completions.list_models()\n",
    "\n",
    "print(model_list)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
